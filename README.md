# ğŸ¤–ğŸ“ CallSense â€“ AI-Powered Customer Support Agent

A real-time AI assistant system for customer support agents that transcribes live conversations and provides intelligent recommendations using RAG and AI agents.

## ğŸ§  System Architecture

![System Architecture](assets/images/system_architecture.png)

## What it does

Transcribes ongoing conversations with speaker labels.
Uses LLMs to generate actionable tasks based on the dialog.
Verifies customer and order details by fetching from internal RAG-powered DB.
Validates refund eligibility based on company policies.
Executes actions through an AI agent using Playwright, such as issuing refunds or updating status.
Provides feedback and policy-verification responses in real time.

## Features

- ğŸ¤ Real-time speech-to-text transcription
- ğŸ¤– LLM-powered task generation from conversations
- ğŸ“š RAG-based knowledge retrieval
- ğŸ”„ Intelligent task orchestration
- ğŸ’¬ Gradio-based frontend with live updates
- ğŸ—ï¸ Modular, extensible architecture

:

## ğŸš€ Project Submission Info
ğŸ¯ This project was built as part of [AgentHacks](https://www.agenthacks.org) â€” a hackathon focused on pushing the boundaries of agent-based AI systems.

ğŸ› ï¸ Main Project Page: ğŸ”— [Weekday â€“ Devpost Submission](https://devpost.com/software/weekday)

ğŸ“½ï¸ [Watch Demo Video on YouTube](https://www.youtube.com/watch?v=PIxKVSEkmiQ)


## Quick Start

### Prerequisites

- Python 3.10+
- [uv](https://github.com/astral-sh/uv) package manager

### Installation

1. Clone the repository:
```bash
git clone <your-repo-url>
cd customer-support-ai
```

2. Create and activate a virtual environment with uv:
```bash
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install dependencies:
```bash
uv pip install -r requirements.txt
```

4. (Optional) Set up OpenAI API key:
```bash
echo "OPENAI_API_KEY=your_api_key_here" > .env
```

### Running the Application

```bash
python main.py
```

The application will launch at `http://localhost:7860`

## Project Structure

```
â”œâ”€â”€ main.py                 # Application entry point
â”œâ”€â”€ components/            # Core system components
â”‚   â”œâ”€â”€ speech_to_text.py  # Transcription service
â”‚   â”œâ”€â”€ llm_service.py     # LLM task generation
â”‚   â”œâ”€â”€ orchestrator.py    # Task routing logic
â”‚   â”œâ”€â”€ rag_service.py     # Knowledge retrieval
â”‚   â”œâ”€â”€ ai_agent.py        # AI agent actions
â”‚   â””â”€â”€ state_manager.py   # Central state control
â”œâ”€â”€ frontend/              # UI components
â”‚   â””â”€â”€ gradio_app.py      # Gradio interface
â”œâ”€â”€ data/                  # Knowledge base
â”‚   â”œâ”€â”€ knowledge_base.json
â”‚   â””â”€â”€ policies.txt
â””â”€â”€ utils/                 # Shared utilities
    â””â”€â”€ models.py          # Data models
```

## Usage

1. **Start the application** - The system begins with mock transcription
2. **Monitor conversation** - Watch the real-time transcript in the left panel
3. **Trigger AI assistance** - Click "ğŸ¤– Generate AI Assistance" button
4. **Review recommendations** - AI suggestions appear in the right panel
5. **Execute or reject** - Choose to apply or dismiss the AI recommendations




## Development

### Using uv for package management

```bash
# Add a new dependency
uv pip install package-name

# Update requirements
uv pip freeze > requirements.txt

# Install from requirements
uv pip sync requirements.txt
```

### Running tests (when added)
```bash
uv run pytest
```

## Configuration

Edit `config.py` to modify:
- LLM model selection
- API endpoints
- File paths
- Server settings

## MVP Limitations

- Uses mock speech-to-text (no real audio processing)
- Mock AI agent actions (no actual MCP integration)
- File-based RAG (no vector database)
- Single conversation support

## Roadmap

- [ ] Integrate real speech-to-text API
- [ ] Implement MCP (Model Context Protocol)
- [ ] Add Playwright for web automation
- [ ] Vector database for RAG
- [ ] Multi-conversation support
- [ ] Authentication system
